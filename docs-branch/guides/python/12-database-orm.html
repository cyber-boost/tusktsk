<h1>Database and ORM Integration in TuskLang Python</h1>

<h2>Advanced Database Configuration</h2>
<p>TuskLang provides comprehensive database and ORM integration for Python applications including SQLAlchemy, Django ORM, and custom database configurations.</p>

<h3>database.tsk</h3>
<pre>
# Database Connection Configuration
database {
    # Primary database
    primary {
        engine: "postgresql"
        host: env("DB_HOST", "localhost")
        port: env("DB_PORT", 5432)
        name: env("DB_NAME", "myapp")
        user: env("DB_USER", "postgres")
        password: env("DB_PASSWORD", "")
        
        # Connection URL construction
        url: "postgresql://${database.primary.user}:${database.primary.password}@${database.primary.host}:${database.primary.port}/${database.primary.name}"
        
        # SQLAlchemy settings
        pool_size: env("DB_POOL_SIZE", 20)
        max_overflow: env("DB_MAX_OVERFLOW", 30)
        pool_timeout: env("DB_POOL_TIMEOUT", 30)
        pool_recycle: env("DB_POOL_RECYCLE", 3600)
        echo: env("DB_ECHO", false)
        echo_pool: env("DB_ECHO_POOL", false)
        
        # Connection options
        connect_args: {
            sslmode: env("DB_SSL_MODE", "prefer")
            connect_timeout: 10
            application_name: "tusklang_app"
            options: "-c timezone=UTC"
        }
    }
    
    # Read replica
    replica {
        engine: "postgresql"
        host: env("DB_REPLICA_HOST", "replica.example.com")
        port: env("DB_REPLICA_PORT", 5432)
        name: "${database.primary.name}"
        user: "${database.primary.user}"
        password: "${database.primary.password}"
        url: "postgresql://${database.replica.user}:${database.replica.password}@${database.replica.host}:${database.replica.port}/${database.replica.name}"
        
        pool_size: 10
        max_overflow: 20
        readonly: true
    }
    
    # Analytics database
    analytics {
        engine: "clickhouse"
        host: env("ANALYTICS_DB_HOST", "analytics.example.com")
        port: env("ANALYTICS_DB_PORT", 8123)
        name: env("ANALYTICS_DB_NAME", "analytics")
        user: env("ANALYTICS_DB_USER", "analytics")
        password: env("ANALYTICS_DB_PASSWORD", "")
        url: "clickhouse://${database.analytics.user}:${database.analytics.password}@${database.analytics.host}:${database.analytics.port}/${database.analytics.name}"
    }
}

# ORM Configuration
orm {
    # SQLAlchemy configuration
    sqlalchemy {
        # Base configuration
        database_url: "${database.primary.url}"
        echo: "${database.primary.echo}"
        echo_pool: "${database.primary.echo_pool}"
        
        # Session configuration
        session {
            autocommit: false
            autoflush: true
            expire_on_commit: true
            
            # Transaction isolation level
            isolation_level: env("DB_ISOLATION_LEVEL", "READ_COMMITTED")
        }
        
        # Engine options
        engine_options: {
            pool_size: "${database.primary.pool_size}"
            max_overflow: "${database.primary.max_overflow}"
            pool_timeout: "${database.primary.pool_timeout}"
            pool_recycle: "${database.primary.pool_recycle}"
            pool_pre_ping: true
            connect_args: "${database.primary.connect_args}"
        }
        
        # Migration settings
        migrations {
            directory: "migrations"
            version_table: "alembic_version"
            compare_type: true
            compare_server_default: true
            render_as_batch: env("DB_BATCH_MIGRATIONS", false)
        }
    }
    
    # Django ORM configuration
    django {
        default: {
            ENGINE: "django.db.backends.postgresql"
            NAME: "${database.primary.name}"
            USER: "${database.primary.user}"
            PASSWORD: "${database.primary.password}"
            HOST: "${database.primary.host}"
            PORT: "${database.primary.port}"
            
            OPTIONS: {
                sslmode: "${database.primary.connect_args.sslmode}"
                connect_timeout: "${database.primary.connect_args.connect_timeout}"
                application_name: "${database.primary.connect_args.application_name}"
            }
            
            CONN_MAX_AGE: env("DB_CONN_MAX_AGE", 60)
            ATOMIC_REQUESTS: env("DB_ATOMIC_REQUESTS", true)
        }
        
        replica: {
            ENGINE: "django.db.backends.postgresql"
            NAME: "${database.replica.name}"
            USER: "${database.replica.user}"
            PASSWORD: "${database.replica.password}"
            HOST: "${database.replica.host}"
            PORT: "${database.replica.port}"
        }
    }
}

# Cache Configuration
cache {
    # Redis cache
    redis {
        host: env("REDIS_HOST", "localhost")
        port: env("REDIS_PORT", 6379)
        db: env("REDIS_DB", 0)
        password: env("REDIS_PASSWORD", "")
        url: "redis://:${cache.redis.password}@${cache.redis.host}:${cache.redis.port}/${cache.redis.db}"
        
        # Connection pool settings
        connection_pool: {
            max_connections: env("REDIS_MAX_CONNECTIONS", 100)
            socket_timeout: env("REDIS_SOCKET_TIMEOUT", 5)
            socket_keepalive: true
            socket_keepalive_options: {}
            retry_on_timeout: true
        }
        
        # Cache key prefix
        key_prefix: env("CACHE_KEY_PREFIX", "tusklang:")
        version: env("CACHE_VERSION", 1)
        
        # Serialization
        serializer: "json"  # json, pickle, msgpack
        compressor: "gzip"  # gzip, lz4, none
    }
    
    # Memcached cache
    memcached {
        servers: env("MEMCACHED_SERVERS", "127.0.0.1:11211").split(",")
        binary: true
        behaviors: {
            tcp_nodelay: true
            ketama: true
        }
    }
    
    # Database cache
    database {
        table: "cache_table"
        max_entries: 300
        cull_frequency: 3
    }
}

# Query Configuration
queries {
    # Default query settings
    defaults {
        timeout: env("QUERY_TIMEOUT", 30)
        retry_attempts: env("QUERY_RETRY_ATTEMPTS", 3)
        retry_delay: env("QUERY_RETRY_DELAY", 1)
        slow_query_threshold: env("SLOW_QUERY_THRESHOLD", 1000)
    }
    
    # Query logging
    logging {
        enabled: env("QUERY_LOGGING", false)
        log_slow_queries: true
        log_all_queries: env("LOG_ALL_QUERIES", false)
        log_parameters: env("LOG_QUERY_PARAMS", false)
    }
    
    # Query optimization
    optimization {
        enable_query_cache: env("ENABLE_QUERY_CACHE", true)
        cache_ttl: env("QUERY_CACHE_TTL", 300)
        enable_connection_pooling: true
        enable_prepared_statements: true
    }
}

# Model Configuration
models {
    # Base model settings
    base {
        # Automatic timestamps
        timestamps: true
        created_at_field: "created_at"
        updated_at_field: "updated_at"
        
        # Soft deletes
        soft_deletes: env("ENABLE_SOFT_DELETES", false)
        deleted_at_field: "deleted_at"
        
        # UUID primary keys
        use_uuid_pk: env("USE_UUID_PK", false)
        uuid_field: "id"
    }
    
    # Validation settings
    validation {
        strict_mode: env("MODEL_VALIDATION_STRICT", true)
        auto_validate: true
        validate_on_save: true
        validate_on_update: true
    }
    
    # Serialization
    serialization {
        default_fields: ["id", "created_at", "updated_at"]
        exclude_fields: ["password", "secret_key"]
        date_format: "iso"
        include_relationships: false
    }
}

# Migration Configuration
migrations {
    # Directory structure
    directories {
        migrations: "migrations"
        models: "models"
        seeds: "seeds"
    }
    
    # Naming conventions
    naming {
        table_prefix: env("TABLE_PREFIX", "")
        foreign_key_format: "{table}_id"
        index_format: "idx_{table}_{columns}"
        constraint_format: "ck_{table}_{constraint}"
    }
    
    # Migration settings
    settings {
        auto_generate: env("AUTO_GENERATE_MIGRATIONS", false)
        backup_before_migrate: env("BACKUP_BEFORE_MIGRATE", true)
        transaction_per_migration: true
        compare_type: true
        compare_server_default: true
    }
}

# Connection Monitoring
monitoring {
    # Health checks
    health_check {
        enabled: true
        interval: env("DB_HEALTH_CHECK_INTERVAL", 30)
        timeout: env("DB_HEALTH_CHECK_TIMEOUT", 5)
        query: "SELECT 1"
    }
    
    # Metrics collection
    metrics {
        enabled: env("DB_METRICS_ENABLED", true)
        collection_interval: env("DB_METRICS_INTERVAL", 60)
        
        # Collected metrics
        collect: [
            "connection_count",
            "active_connections",
            "query_count",
            "slow_query_count",
            "error_count",
            "response_time"
        ]
    }
    
    # Alerting
    alerts {
        slow_query_threshold: "${queries.defaults.slow_query_threshold}"
        connection_threshold: env("DB_CONNECTION_ALERT_THRESHOLD", 80)
        error_rate_threshold: env("DB_ERROR_RATE_THRESHOLD", 5)
    }
}

# Database-specific TuskLang Functions
database_functions {
    # Query builder
    user_query: @Query("User").where("active", true).orderBy("created_at", "desc")
    recent_posts: @Query("Post").where("created_at", ">", @days_ago(7)).limit(10)
    
    # Aggregations
    user_count: @Query("User").count()
    total_revenue: @Query("Order").where("status", "completed").sum("amount")
    
    # Relationships
    user_with_posts: @Query("User").with("posts").where("id", @request.user_id).first()
    
    # Raw queries
    complex_report: @Raw("""
        SELECT u.name, COUNT(p.id) as post_count, AVG(p.likes) as avg_likes
        FROM users u
        LEFT JOIN posts p ON u.id = p.user_id
        WHERE u.active = true
        GROUP BY u.id, u.name
        ORDER BY post_count DESC
        LIMIT 10
    """)
    
    # Cached queries
    popular_tags: @cache("1h", @Query("Tag").orderBy("usage_count", "desc").limit(20))
    
    # Transactions
    transfer_funds: @transaction([
        @Query("Account").where("id", @var.from_account).decrement("balance", @var.amount),
        @Query("Account").where("id", @var.to_account).increment("balance", @var.amount),
        @Query("Transaction").create({
            from_account: @var.from_account,
            to_account: @var.to_account,
            amount: @var.amount,
            type: "transfer"
        })
    ])
}
</pre>

<h3>Python Database Integration Implementation</h3>
<pre>
import os
import logging
from typing import Any, Dict, List, Optional, Union, Type
from contextlib import contextmanager
from datetime import datetime, timedelta
import redis
import sqlalchemy as sa
from sqlalchemy import create_engine, MetaData, Table
from sqlalchemy.orm import sessionmaker, scoped_session, declarative_base
from sqlalchemy.pool import QueuePool
import asyncio
import asyncpg

class DatabaseConfig:
    """Database configuration management."""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.engines = {}
        self.sessions = {}
        self.connections = {}
        
    def get_database_url(self, database_name: str = 'primary') -> str:
        """Get database URL for specified database."""
        db_config = self.config.get('database', {}).get(database_name, {})
        return db_config.get('url', '')
    
    def get_engine(self, database_name: str = 'primary') -> sa.Engine:
        """Get SQLAlchemy engine for database."""
        if database_name not in self.engines:
            url = self.get_database_url(database_name)
            engine_options = self._get_engine_options(database_name)
            self.engines[database_name] = create_engine(url, **engine_options)
        
        return self.engines[database_name]
    
    def get_session(self, database_name: str = 'primary'):
        """Get SQLAlchemy session for database."""
        if database_name not in self.sessions:
            engine = self.get_engine(database_name)
            session_factory = sessionmaker(bind=engine)
            self.sessions[database_name] = scoped_session(session_factory)
        
        return self.sessions[database_name]
    
    def _get_engine_options(self, database_name: str) -> Dict[str, Any]:
        """Get engine options for database."""
        db_config = self.config.get('database', {}).get(database_name, {})
        orm_config = self.config.get('orm', {}).get('sqlalchemy', {})
        
        options = {
            'pool_size': db_config.get('pool_size', 20),
            'max_overflow': db_config.get('max_overflow', 30),
            'pool_timeout': db_config.get('pool_timeout', 30),
            'pool_recycle': db_config.get('pool_recycle', 3600),
            'echo': db_config.get('echo', False),
            'echo_pool': db_config.get('echo_pool', False),
            'poolclass': QueuePool,
        }
        
        connect_args = db_config.get('connect_args', {})
        if connect_args:
            options['connect_args'] = connect_args
        
        return options

class QueryBuilder:
    """TuskLang query builder for Python ORMs."""
    
    def __init__(self, model_class: Type, session):
        self.model_class = model_class
        self.session = session
        self.query = session.query(model_class)
        self._conditions = []
        self._order_clauses = []
        self._limit_value = None
        self._offset_value = None
        self._with_relations = []
    
    def where(self, field: str, operator: str, value: Any = None):
        """Add WHERE condition."""
        if value is None:
            # Single argument case: where(field, value)
            value = operator
            operator = '='
        
        attr = getattr(self.model_class, field, None)
        if attr is None:
            raise ValueError(f"Field {field} not found in {self.model_class.__name__}")
        
        if operator == '=':
            condition = attr == value
        elif operator == '!=':
            condition = attr != value
        elif operator == '>':
            condition = attr > value
        elif operator == '>=':
            condition = attr >= value
        elif operator == '<':
            condition = attr < value
        elif operator == '<=':
            condition = attr <= value
        elif operator.lower() == 'like':
            condition = attr.like(value)
        elif operator.lower() == 'in':
            condition = attr.in_(value)
        else:
            raise ValueError(f"Unsupported operator: {operator}")
        
        self._conditions.append(condition)
        return self
    
    def orderBy(self, field: str, direction: str = 'asc'):
        """Add ORDER BY clause."""
        attr = getattr(self.model_class, field, None)
        if attr is None:
            raise ValueError(f"Field {field} not found in {self.model_class.__name__}")
        
        if direction.lower() == 'desc':
            order_clause = attr.desc()
        else:
            order_clause = attr.asc()
        
        self._order_clauses.append(order_clause)
        return self
    
    def limit(self, count: int):
        """Add LIMIT clause."""
        self._limit_value = count
        return self
    
    def offset(self, count: int):
        """Add OFFSET clause."""
        self._offset_value = count
        return self
    
    def with_relations(self, *relations):
        """Eager load relationships."""
        self._with_relations.extend(relations)
        return self
    
    def _build_query(self):
        """Build the final query."""
        query = self.query
        
        # Apply WHERE conditions
        for condition in self._conditions:
            query = query.filter(condition)
        
        # Apply ORDER BY
        for order_clause in self._order_clauses:
            query = query.order_by(order_clause)
        
        # Apply eager loading
        for relation in self._with_relations:
            query = query.options(sa.orm.joinedload(relation))
        
        # Apply LIMIT and OFFSET
        if self._limit_value is not None:
            query = query.limit(self._limit_value)
        
        if self._offset_value is not None:
            query = query.offset(self._offset_value)
        
        return query
    
    def first(self):
        """Get first result."""
        return self._build_query().first()
    
    def all(self):
        """Get all results."""
        return self._build_query().all()
    
    def count(self):
        """Get count of results."""
        return self._build_query().count()
    
    def paginate(self, page: int, per_page: int):
        """Paginate results."""
        offset = (page - 1) * per_page
        query = self._build_query().offset(offset).limit(per_page)
        
        total = self.count()
        items = query.all()
        
        return {
            'items': items,
            'total': total,
            'page': page,
            'per_page': per_page,
            'pages': (total + per_page - 1) // per_page
        }
    
    def sum(self, field: str):
        """Sum a field."""
        attr = getattr(self.model_class, field, None)
        if attr is None:
            raise ValueError(f"Field {field} not found in {self.model_class.__name__}")
        
        query = self.session.query(sa.func.sum(attr))
        for condition in self._conditions:
            query = query.filter(condition)
        
        result = query.scalar()
        return result or 0
    
    def avg(self, field: str):
        """Average a field."""
        attr = getattr(self.model_class, field, None)
        if attr is None:
            raise ValueError(f"Field {field} not found in {self.model_class.__name__}")
        
        query = self.session.query(sa.func.avg(attr))
        for condition in self._conditions:
            query = query.filter(condition)
        
        result = query.scalar()
        return float(result) if result is not None else 0.0

class TuskLangORM:
    """TuskLang ORM integration."""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.db_config = DatabaseConfig(config)
        self.cache = self._init_cache()
        self.logger = logging.getLogger(__name__)
        
        # Create base model
        self.Base = declarative_base()
        self._models = {}
    
    def _init_cache(self):
        """Initialize cache backend."""
        cache_config = self.config.get('cache', {}).get('redis', {})
        if cache_config:
            try:
                return redis.Redis(
                    host=cache_config.get('host', 'localhost'),
                    port=cache_config.get('port', 6379),
                    db=cache_config.get('db', 0),
                    password=cache_config.get('password', ''),
                    decode_responses=True
                )
            except Exception as e:
                self.logger.warning(f"Failed to initialize Redis cache: {e}")
        
        return None
    
    def register_model(self, name: str, model_class: Type):
        """Register a model class."""
        self._models[name] = model_class
    
    def Query(self, model_name: str, database: str = 'primary'):
        """Create a query builder for model."""
        if model_name not in self._models:
            raise ValueError(f"Model {model_name} not registered")
        
        model_class = self._models[model_name]
        session = self.db_config.get_session(database)
        
        return QueryBuilder(model_class, session)
    
    def Raw(self, sql: str, params: Optional[Dict] = None, database: str = 'primary'):
        """Execute raw SQL query."""
        engine = self.db_config.get_engine(database)
        
        with engine.connect() as conn:
            if params:
                result = conn.execute(sa.text(sql), params)
            else:
                result = conn.execute(sa.text(sql))
            
            return result.fetchall()
    
    @contextmanager
    def transaction(self, database: str = 'primary'):
        """Transaction context manager."""
        session = self.db_config.get_session(database)
        
        try:
            yield session
            session.commit()
        except Exception:
            session.rollback()
            raise
        finally:
            session.close()
    
    def cache_query(self, key: str, ttl: int, query_func, *args, **kwargs):
        """Cache query results."""
        if not self.cache:
            return query_func(*args, **kwargs)
        
        # Try to get from cache
        try:
            cached_result = self.cache.get(key)
            if cached_result:
                import json
                return json.loads(cached_result)
        except Exception as e:
            self.logger.warning(f"Cache get error: {e}")
        
        # Execute query
        result = query_func(*args, **kwargs)
        
        # Store in cache
        try:
            import json
            self.cache.setex(key, ttl, json.dumps(result, default=str))
        except Exception as e:
            self.logger.warning(f"Cache set error: {e}")
        
        return result

# Example model definitions
def create_example_models(Base):
    """Create example models for demonstration."""
    
    class User(Base):
        __tablename__ = 'users'
        
        id = sa.Column(sa.Integer, primary_key=True)
        username = sa.Column(sa.String(80), unique=True, nullable=False)
        email = sa.Column(sa.String(120), unique=True, nullable=False)
        active = sa.Column(sa.Boolean, default=True)
        created_at = sa.Column(sa.DateTime, default=datetime.utcnow)
        updated_at = sa.Column(sa.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
        
        # Relationship
        posts = sa.orm.relationship('Post', back_populates='author')
    
    class Post(Base):
        __tablename__ = 'posts'
        
        id = sa.Column(sa.Integer, primary_key=True)
        title = sa.Column(sa.String(200), nullable=False)
        content = sa.Column(sa.Text)
        likes = sa.Column(sa.Integer, default=0)
        user_id = sa.Column(sa.Integer, sa.ForeignKey('users.id'))
        created_at = sa.Column(sa.DateTime, default=datetime.utcnow)
        
        # Relationship
        author = sa.orm.relationship('User', back_populates='posts')
    
    return User, Post

# Example usage
def demonstrate_database_integration():
    """Demonstrate database integration."""
    
    # Sample configuration
    config = {
        'database': {
            'primary': {
                'url': 'sqlite:///example.db',
                'pool_size': 5,
                'echo': True
            }
        },
        'cache': {
            'redis': {
                'host': 'localhost',
                'port': 6379,
                'db': 0
            }
        }
    }
    
    # Initialize ORM
    orm = TuskLangORM(config)
    
    # Create models
    User, Post = create_example_models(orm.Base)
    
    # Register models
    orm.register_model('User', User)
    orm.register_model('Post', Post)
    
    # Create tables
    engine = orm.db_config.get_engine()
    orm.Base.metadata.create_all(engine)
    
    # Example queries
    print("Database Integration Demo:")
    print("=" * 50)
    
    # Query active users
    active_users = orm.Query('User').where('active', True).all()
    print(f"Active users: {len(active_users)}")
    
    # Get user with posts
    user_with_posts = orm.Query('User').with_relations('posts').first()
    if user_with_posts:
        print(f"User: {user_with_posts.username}")
    
    # Count posts
    post_count = orm.Query('Post').count()
    print(f"Total posts: {post_count}")
    
    # Raw query example
    try:
        results = orm.Raw("SELECT COUNT(*) as total FROM users WHERE active = :active", 
                         {'active': True})
        print(f"Raw query result: {results}")
    except Exception as e:
        print(f"Raw query error: {e}")

if __name__ == "__main__":
    demonstrate_database_integration()
</pre>

<p>TuskLang's database integration provides comprehensive ORM support for Python applications with advanced query building, caching, and multiple database backend support.</p>