<h1>Advanced Features for Java</h1>

<h2>Reactive Programming Integration</h2>
<pre>
# Reactive programming configuration
reactive: {
    # WebFlux configuration
    webflux: {
        enabled: env("REACTIVE_ENABLED", "false") == "true"
        
        # Netty server configuration
        netty: {
            # Event loop configuration
            event_loop_threads: java("Runtime.getRuntime().availableProcessors() * 2")
            worker_threads: java("Runtime.getRuntime().availableProcessors() * 4")
            
            # Buffer settings
            max_initial_line_length: 4096
            max_header_size: 8192
            max_chunk_size: 8192
            
            # Connection settings
            connection_timeout: "30s"
            so_keepalive: true
            tcp_nodelay: true
        }
        
        # Reactive data access
        r2dbc: {
            enabled: reactive.webflux.enabled
            url: "r2dbc:postgresql://" + env("DB_HOST", "localhost") + ":" + env("DB_PORT", "5432") + "/" + env("DB_NAME", "myapp")
            username: env("DB_USER", "postgres")
            password: env("DB_PASS")
            
            # Connection pool
            pool: {
                initial_size: 10
                max_size: 20
                max_idle_time: "30m"
                max_life_time: "1h"
                max_acquire_time: "60s"
                max_create_connection_time: "30s"
            }
        }
        
        # Reactive cache
        reactive_cache: {
            enabled: reactive.webflux.enabled
            provider: "redis"  # redis, caffeine
            
            redis: {
                host: env("REDIS_HOST", "localhost")
                port: env("REDIS_PORT", "6379")
                timeout: "5s"
                
                # Reactive Redis settings
                command_timeout: "3s"
                netty_threads: java("Runtime.getRuntime().availableProcessors()")
            }
        }
    }
    
    # Project Reactor configuration
    reactor: {
        # Scheduler configuration
        schedulers: {
            # Parallel scheduler
            parallel: {
                size: java("Runtime.getRuntime().availableProcessors()")
                thread_name: "reactor-parallel"
            }
            
            # Elastic scheduler
            elastic: {
                ttl_seconds: 60
                thread_name: "reactor-elastic"
            }
            
            # Single scheduler
            single: {
                thread_name: "reactor-single"
            }
        }
        
        # Buffer and batch settings
        buffer_size: {
            small: 256
            default: 1024
            large: 4096
        }
        
        # Backpressure configuration
        backpressure: {
            strategy: "BUFFER"  # BUFFER, DROP, LATEST, ERROR
            buffer_capacity: 1000
        }
        
        # Debugging and monitoring
        debug: env("REACTOR_DEBUG", "false") == "true"
        metrics: env("REACTOR_METRICS", "true") == "true"
    }
    
    # RSocket configuration
    rsocket: {
        enabled: env("RSOCKET_ENABLED", "false") == "true"
        
        # Server configuration
        server: {
            port: env("RSOCKET_PORT", "9898")
            transport: "tcp"  # tcp, websocket
            
            # Frame settings
            max_frame_length: 16777215  # 16MB
            max_inbound_payload_size: 16777215
            
            # Keepalive settings
            keepalive_interval: "20s"
            keepalive_max_lifetime: "90s"
        }
        
        # Client configuration
        client: {
            # Connection settings
            connect_timeout: "30s"
            keepalive_interval: "20s"
            keepalive_max_lifetime: "90s"
            
            # Load balancing
            load_balancer: "round_robin"  # round_robin, weighted, random
        }
    }
}
</pre>

<h2>Java Reactive Configuration</h2>
<pre>
// ReactiveConfiguration.java
@Configuration
@ConditionalOnProperty(name = "reactive.webflux.enabled", havingValue = "true")
@EnableWebFlux
@EnableR2dbcRepositories
public class ReactiveConfiguration implements WebFluxConfigurer {
    
    @Value("#{${reactive.webflux.netty}}")
    private Map&lt;String, Object&gt; nettyConfig;
    
    @Value("#{${reactive.r2dbc}}")
    private Map&lt;String, Object&gt; r2dbcConfig;
    
    @Value("#{${reactive.reactor}}")
    private Map&lt;String, Object&gt; reactorConfig;
    
    @Bean
    public NettyReactiveWebServerFactory nettyReactiveWebServerFactory() {
        NettyReactiveWebServerFactory factory = new NettyReactiveWebServerFactory();
        
        factory.addServerCustomizers(httpServer -&gt; {
            // Configure event loop threads
            Integer eventLoopThreads = (Integer) nettyConfig.get("event_loop_threads");
            if (eventLoopThreads != null) {
                return httpServer.runOn(LoopResources.create("http", eventLoopThreads, true));
            }
            return httpServer;
        });
        
        return factory;
    }
    
    @Bean
    public ConnectionFactory connectionFactory() {
        Map&lt;String, Object&gt; pool = (Map&lt;String, Object&gt;) r2dbcConfig.get("pool");
        
        ConnectionFactoryOptions options = ConnectionFactoryOptions.builder()
            .option(ConnectionFactoryOptions.DRIVER, "postgresql")
            .option(ConnectionFactoryOptions.HOST, getHost())
            .option(ConnectionFactoryOptions.PORT, getPort())
            .option(ConnectionFactoryOptions.DATABASE, getDatabase())
            .option(ConnectionFactoryOptions.USER, getUsername())
            .option(ConnectionFactoryOptions.PASSWORD, getPassword())
            .build();
        
        ConnectionFactory connectionFactory = ConnectionFactories.get(options);
        
        // Configure connection pool
        if (pool != null) {
            ConnectionPoolConfiguration poolConfig = ConnectionPoolConfiguration.builder(connectionFactory)
                .initialSize((Integer) pool.get("initial_size"))
                .maxSize((Integer) pool.get("max_size"))
                .maxIdleTime(Duration.parse("PT" + pool.get("max_idle_time")))
                .maxLifeTime(Duration.parse("PT" + pool.get("max_life_time")))
                .maxAcquireTime(Duration.parse("PT" + pool.get("max_acquire_time")))
                .maxCreateConnectionTime(Duration.parse("PT" + pool.get("max_create_connection_time")))
                .build();
            
            return new ConnectionPool(poolConfig);
        }
        
        return connectionFactory;
    }
    
    @Bean
    public ReactiveRedisTemplate&lt;String, Object&gt; reactiveRedisTemplate() {
        Map&lt;String, Object&gt; redisConfig = (Map&lt;String, Object&gt;) 
            ((Map&lt;String, Object&gt;) getValue("reactive.reactive_cache")).get("redis");
        
        if (redisConfig == null) {
            return null;
        }
        
        String host = (String) redisConfig.get("host");
        Integer port = (Integer) redisConfig.get("port");
        
        LettuceConnectionFactory connectionFactory = new LettuceConnectionFactory(host, port);
        
        // Configure client resources
        Integer nettyThreads = (Integer) redisConfig.get("netty_threads");
        if (nettyThreads != null) {
            DefaultClientResources clientResources = DefaultClientResources.builder()
                .ioThreadPoolSize(nettyThreads)
                .computationThreadPoolSize(nettyThreads)
                .build();
            
            connectionFactory.setClientResources(clientResources);
        }
        
        connectionFactory.afterPropertiesSet();
        
        ReactiveRedisTemplate&lt;String, Object&gt; template = new ReactiveRedisTemplate&lt;&gt;(
            connectionFactory, 
            RedisSerializationContext.string()
        );
        
        return template;
    }
    
    @PostConstruct
    public void configureReactor() {
        Map&lt;String, Object&gt; schedulers = (Map&lt;String, Object&gt;) reactorConfig.get("schedulers");
        
        if (schedulers != null) {
            Map&lt;String, Object&gt; parallel = (Map&lt;String, Object&gt;) schedulers.get("parallel");
            if (parallel != null) {
                Integer size = (Integer) parallel.get("size");
                String threadName = (String) parallel.get("thread_name");
                
                Schedulers.setFactory(new Schedulers.Factory() {
                    @Override
                    public Scheduler newParallel(int parallelism, ThreadFactory threadFactory) {
                        return Schedulers.newParallel(threadName, size != null ? size : parallelism);
                    }
                });
            }
        }
        
        // Configure debugging
        Boolean debug = (Boolean) reactorConfig.get("debug");
        if (debug != null && debug) {
            Hooks.onOperatorDebug();
        }
        
        // Configure metrics
        Boolean metrics = (Boolean) reactorConfig.get("metrics");
        if (metrics != null && metrics) {
            Metrics.addRegistry(new PrometheusMeterRegistry(PrometheusConfig.DEFAULT));
        }
    }
    
    private String getHost() {
        String url = (String) r2dbcConfig.get("url");
        // Parse host from R2DBC URL
        return url.substring(url.indexOf("://") + 3, url.lastIndexOf(":"));
    }
    
    private int getPort() {
        String url = (String) r2dbcConfig.get("url");
        // Parse port from R2DBC URL
        String portStr = url.substring(url.lastIndexOf(":") + 1, url.lastIndexOf("/"));
        return Integer.parseInt(portStr);
    }
    
    private String getDatabase() {
        String url = (String) r2dbcConfig.get("url");
        // Parse database from R2DBC URL
        return url.substring(url.lastIndexOf("/") + 1);
    }
    
    private String getUsername() {
        return (String) r2dbcConfig.get("username");
    }
    
    private String getPassword() {
        return (String) r2dbcConfig.get("password");
    }
}
</pre>

<h2>Microservices Architecture Integration</h2>
<pre>
# Microservices configuration
microservices: {
    # Service discovery
    discovery: {
        type: env("DISCOVERY_TYPE", "eureka")  # eureka, consul, nacos
        
        # Eureka configuration
        eureka: {
            enabled: microservices.discovery.type == "eureka"
            server_url: env("EUREKA_SERVER_URL", "http://localhost:8761/eureka")
            
            # Instance configuration
            instance: {
                hostname: env("INSTANCE_HOSTNAME", java("java.net.InetAddress.getLocalHost().getHostName()"))
                prefer_ip_address: env("EUREKA_PREFER_IP", "true") == "true"
                lease_renewal_interval: 30
                lease_expiration_duration: 90
                
                # Health check
                health_check_url_path: "/actuator/health"
                status_page_url_path: "/actuator/info"
            }
            
            # Client configuration
            client: {
                register_with_eureka: true
                fetch_registry: true
                registry_fetch_interval: 30
                cache_refresh_executor_threads: 2
                heartbeat_executor_threads: 2
            }
        }
        
        # Consul configuration
        consul: {
            enabled: microservices.discovery.type == "consul"
            host: env("CONSUL_HOST", "localhost")
            port: env("CONSUL_PORT", "8500")
            
            # Discovery configuration
            discovery: {
                health_check_interval: "10s"
                health_check_timeout: "3s"
                health_check_critical_timeout: "1m"
                
                # Service tags
                tags: [
                    "version=" + env("SERVICE_VERSION", "1.0.0"),
                    "environment=" + env("ENVIRONMENT", "development")
                ]
                
                # Instance metadata
                metadata: {
                    version: env("SERVICE_VERSION", "1.0.0")
                    environment: env("ENVIRONMENT", "development")
                    region: env("SERVICE_REGION", "us-east-1")
                }
            }
        }
    }
    
    # Load balancing
    load_balancing: {
        # Client-side load balancing
        ribbon: {
            enabled: env("RIBBON_ENABLED", "true") == "true"
            
            # Load balancing rule
            rule: env("RIBBON_RULE", "RoundRobinRule")  # RoundRobinRule, WeightedResponseTimeRule, AvailabilityFilteringRule
            
            # Ping configuration
            ping_interval: 30
            max_auto_retries: 1
            max_auto_retries_next_server: 1
            
            # Connection settings
            connect_timeout: 5000
            read_timeout: 5000
            
            # Circuit breaker integration
            circuit_breaker_enabled: true
        }
        
        # Spring Cloud LoadBalancer
        spring_cloud_lb: {
            enabled: env("SPRING_CLOUD_LB_ENABLED", "true") == "true"
            
            # Health check
            health_check: {
                enabled: true
                interval: "25s"
                path: "/actuator/health"
            }
            
            # Retry configuration
            retry: {
                enabled: true
                max_retries_on_same_service_instance: 1
                max_retries_on_next_service_instance: 1
                retry_on_all_operations: false
            }
        }
    }
    
    # Circuit breaker
    circuit_breaker: {
        # Hystrix configuration (deprecated but still used)
        hystrix: {
            enabled: env("HYSTRIX_ENABLED", "false") == "true"
            
            # Command configuration
            command: {
                default: {
                    execution: {
                        timeout_enabled: true
                        timeout_in_milliseconds: 5000
                        isolation_strategy: "THREAD"  # THREAD, SEMAPHORE
                    }
                    
                    circuit_breaker: {
                        enabled: true
                        request_volume_threshold: 20
                        error_threshold_percentage: 50
                        sleep_window_in_milliseconds: 5000
                    }
                    
                    fallback: {
                        enabled: true
                        isolation_semaphore_max_concurrent_requests: 10
                    }
                }
            }
            
            # Thread pool configuration
            thread_pool: {
                default: {
                    core_size: 10
                    maximum_size: 10
                    max_queue_size: -1
                    queue_size_rejection_threshold: 5
                    keep_alive_time_minutes: 1
                }
            }
        }
        
        # Resilience4j configuration (recommended)
        resilience4j: {
            enabled: env("RESILIENCE4J_ENABLED", "true") == "true"
            
            # Circuit breaker configuration
            circuit_breaker: {
                instances: {
                    default: {
                        register_health_indicator: true
                        sliding_window_size: 10
                        minimum_number_of_calls: 5
                        permitted_number_of_calls_in_half_open_state: 3
                        wait_duration_in_open_state: "10s"
                        failure_rate_threshold: 50
                        slow_call_rate_threshold: 50
                        slow_call_duration_threshold: "2s"
                    }
                }
            }
            
            # Retry configuration
            retry: {
                instances: {
                    default: {
                        max_attempts: 3
                        wait_duration: "1s"
                        enable_exponential_backoff: true
                        exponential_backoff_multiplier: 2
                        retry_exceptions: [
                            "java.net.ConnectException",
                            "java.net.SocketTimeoutException"
                        ]
                    }
                }
            }
            
            # Bulkhead configuration
            bulkhead: {
                instances: {
                    default: {
                        max_concurrent_calls: 25
                        max_wait_duration: "0ms"
                    }
                }
            }
            
            # Rate limiter configuration
            rate_limiter: {
                instances: {
                    default: {
                        limit_refresh_period: "1s"
                        limit_for_period: 100
                        timeout_duration: "0ms"
                    }
                }
            }
        }
    }
    
    # API Gateway integration
    gateway: {
        enabled: env("GATEWAY_ENABLED", "false") == "true"
        
        # Spring Cloud Gateway
        spring_cloud_gateway: {
            # Global filters
            global_filters: [
                "RequestRateLimiter",
                "CircuitBreaker",
                "Retry",
                "LoadBalancerClient"
            ]
            
            # Route configuration
            routes: [
                {
                    id: "user-service"
                    uri: "lb://user-service"
                    predicates: ["Path=/api/users/**"]
                    filters: [
                        "StripPrefix=2",
                        "CircuitBreaker=user-service"
                    ]
                },
                {
                    id: "order-service"
                    uri: "lb://order-service"
                    predicates: ["Path=/api/orders/**"]
                    filters: [
                        "StripPrefix=2",
                        "CircuitBreaker=order-service"
                    ]
                }
            ]
            
            # Cross-cutting concerns
            cors: {
                allowed_origins: ["http://localhost:3000", "https://myapp.com"]
                allowed_methods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
                allowed_headers: ["*"]
                allow_credentials: true
            }
            
            # Rate limiting
            rate_limiting: {
                redis_rate_limiter: {
                    redis_script_name: "request_rate_limiter"
                    replenish_rate: 10
                    burst_capacity: 20
                    requested_tokens: 1
                }
            }
        }
    }
    
    # Distributed tracing
    tracing: {
        enabled: env("TRACING_ENABLED", "true") == "true"
        
        # Sleuth configuration
        sleuth: {
            sampler: {
                probability: env("SLEUTH_SAMPLE_RATE", "0.1")  # 10% sampling
            }
            
            # Zipkin integration
            zipkin: {
                enabled: env("ZIPKIN_ENABLED", "true") == "true"
                base_url: env("ZIPKIN_BASE_URL", "http://localhost:9411")
                sender_type: "web"  # web, rabbit, kafka
            }
            
            # Jaeger integration
            jaeger: {
                enabled: env("JAEGER_ENABLED", "false") == "true"
                endpoint: env("JAEGER_ENDPOINT", "http://localhost:14268/api/traces")
                
                # Sampling configuration
                const_sampler: {
                    decision: true
                }
                
                # Reporter configuration
                log_spans: true
                max_packet_size: 65000
                flush_interval: "1s"
            }
        }
    }
}
</pre>

<h2>Java Microservices Configuration</h2>
<pre>
// MicroservicesConfiguration.java
@Configuration
@EnableEurekaClient
@EnableCircuitBreaker
@EnableZuulProxy
public class MicroservicesConfiguration {
    
    @Value("#{${microservices.discovery.eureka}}")
    private Map&lt;String, Object&gt; eurekaConfig;
    
    @Value("#{${microservices.circuit_breaker.resilience4j}}")
    private Map&lt;String, Object&gt; resilience4jConfig;
    
    @Bean
    @ConditionalOnProperty(name = "microservices.discovery.eureka.enabled", havingValue = "true")
    public EurekaInstanceConfigBean eurekaInstanceConfig() {
        EurekaInstanceConfigBean config = new EurekaInstanceConfigBean();
        
        Map&lt;String, Object&gt; instance = (Map&lt;String, Object&gt;) eurekaConfig.get("instance");
        if (instance != null) {
            config.setHostname((String) instance.get("hostname"));
            config.setPreferIpAddress((Boolean) instance.get("prefer_ip_address"));
            config.setLeaseRenewalIntervalInSeconds((Integer) instance.get("lease_renewal_interval"));
            config.setLeaseExpirationDurationInSeconds((Integer) instance.get("lease_expiration_duration"));
            config.setHealthCheckUrlPath((String) instance.get("health_check_url_path"));
            config.setStatusPageUrlPath((String) instance.get("status_page_url_path"));
        }
        
        return config;
    }
    
    @Bean
    @ConditionalOnProperty(name = "microservices.circuit_breaker.resilience4j.enabled", havingValue = "true")
    public Customizer&lt;CircuitBreakerRegistry&gt; circuitBreakerRegistryCustomizer() {
        return registry -&gt; {
            Map&lt;String, Object&gt; circuitBreaker = (Map&lt;String, Object&gt;) resilience4jConfig.get("circuit_breaker");
            if (circuitBreaker != null) {
                Map&lt;String, Object&gt; instances = (Map&lt;String, Object&gt;) circuitBreaker.get("instances");
                if (instances != null) {
                    instances.forEach((name, config) -&gt; {
                        Map&lt;String, Object&gt; instanceConfig = (Map&lt;String, Object&gt;) config;
                        
                        CircuitBreakerConfig cbConfig = CircuitBreakerConfig.custom()
                            .slidingWindowSize((Integer) instanceConfig.get("sliding_window_size"))
                            .minimumNumberOfCalls((Integer) instanceConfig.get("minimum_number_of_calls"))
                            .permittedNumberOfCallsInHalfOpenState((Integer) instanceConfig.get("permitted_number_of_calls_in_half_open_state"))
                            .waitDurationInOpenState(Duration.parse("PT" + instanceConfig.get("wait_duration_in_open_state")))
                            .failureRateThreshold(((Number) instanceConfig.get("failure_rate_threshold")).floatValue())
                            .slowCallRateThreshold(((Number) instanceConfig.get("slow_call_rate_threshold")).floatValue())
                            .slowCallDurationThreshold(Duration.parse("PT" + instanceConfig.get("slow_call_duration_threshold")))
                            .build();
                        
                        registry.circuitBreaker(name, cbConfig);
                    });
                }
            }
        };
    }
    
    @Bean
    @ConditionalOnProperty(name = "microservices.circuit_breaker.resilience4j.enabled", havingValue = "true")
    public Customizer&lt;RetryRegistry&gt; retryRegistryCustomizer() {
        return registry -&gt; {
            Map&lt;String, Object&gt; retry = (Map&lt;String, Object&gt;) resilience4jConfig.get("retry");
            if (retry != null) {
                Map&lt;String, Object&gt; instances = (Map&lt;String, Object&gt;) retry.get("instances");
                if (instances != null) {
                    instances.forEach((name, config) -&gt; {
                        Map&lt;String, Object&gt; instanceConfig = (Map&lt;String, Object&gt;) config;
                        
                        RetryConfig retryConfig = RetryConfig.custom()
                            .maxAttempts((Integer) instanceConfig.get("max_attempts"))
                            .waitDuration(Duration.parse("PT" + instanceConfig.get("wait_duration")))
                            .exponentialBackoffMultiplier(((Number) instanceConfig.get("exponential_backoff_multiplier")).doubleValue())
                            .retryOnException(throwable -&gt; {
                                List&lt;String&gt; retryExceptions = (List&lt;String&gt;) instanceConfig.get("retry_exceptions");
                                return retryExceptions.contains(throwable.getClass().getName());
                            })
                            .build();
                        
                        registry.retry(name, retryConfig);
                    });
                }
            }
        };
    }
    
    @Bean
    @LoadBalanced
    public RestTemplate restTemplate() {
        return new RestTemplate();
    }
    
    @Bean
    @LoadBalanced
    public WebClient.Builder webClientBuilder() {
        return WebClient.builder();
    }
}

// Service implementation with circuit breaker
@Service
public class UserServiceClient {
    
    private final WebClient webClient;
    private final CircuitBreaker circuitBreaker;
    private final Retry retry;
    
    public UserServiceClient(WebClient.Builder webClientBuilder) {
        this.webClient = webClientBuilder
            .baseUrl("http://user-service")
            .build();
        
        // Get circuit breaker and retry instances
        this.circuitBreaker = CircuitBreakerRegistry.ofDefaults().circuitBreaker("user-service");
        this.retry = RetryRegistry.ofDefaults().retry("user-service");
    }
    
    public Mono&lt;User&gt; getUserById(Long userId) {
        Supplier&lt;Mono&lt;User&gt;&gt; decoratedSupplier = CircuitBreaker
            .decorateSupplier(circuitBreaker, () -&gt; {
                return webClient
                    .get()
                    .uri("/users/{id}", userId)
                    .retrieve()
                    .bodyToMono(User.class);
            });
        
        // Add retry
        decoratedSupplier = Retry.decorateSupplier(retry, decoratedSupplier);
        
        return decoratedSupplier.get()
            .onErrorResume(this::fallbackGetUser);
    }
    
    private Mono&lt;User&gt; fallbackGetUser(Throwable throwable) {
        // Return a default user or cached user
        User fallbackUser = new User();
        fallbackUser.setId(-1L);
        fallbackUser.setUsername("fallback-user");
        fallbackUser.setEmail("fallback@example.com");
        
        return Mono.just(fallbackUser);
    }
    
    public Flux&lt;User&gt; getAllUsers() {
        return webClient
            .get()
            .uri("/users")
            .retrieve()
            .bodyToFlux(User.class)
            .transform(CircuitBreakerOperator.of(circuitBreaker))
            .transform(RetryOperator.of(retry))
            .onErrorResume(throwable -&gt; {
                // Return empty flux or cached users
                return Flux.empty();
            });
    }
}
</pre>

<h2>Event-Driven Architecture</h2>
<pre>
# Event-driven architecture configuration
events: {
    # Message broker configuration
    broker: {
        type: env("MESSAGE_BROKER", "kafka")  # kafka, rabbitmq, pulsar
        
        # Kafka configuration
        kafka: {
            enabled: events.broker.type == "kafka"
            bootstrap_servers: env("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092")
            
            # Producer configuration
            producer: {
                # Serialization
                key_serializer: "org.apache.kafka.common.serialization.StringSerializer"
                value_serializer: "org.springframework.kafka.support.serializer.JsonSerializer"
                
                # Performance settings
                batch_size: 16384
                linger_ms: 5
                compression_type: "snappy"
                
                # Reliability settings
                acks: "all"
                retries: 3
                max_in_flight_requests_per_connection: 5
                enable_idempotence: true
                
                # Timeout settings
                request_timeout_ms: 30000
                delivery_timeout_ms: 120000
            }
            
            # Consumer configuration
            consumer: {
                # Deserialization
                key_deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
                value_deserializer: "org.springframework.kafka.support.serializer.JsonDeserializer"
                
                # Consumer group settings
                group_id: env("KAFKA_CONSUMER_GROUP", "myapp-group")
                auto_offset_reset: "earliest"
                enable_auto_commit: false
                
                # Fetch settings
                fetch_min_bytes: 1
                fetch_max_wait_ms: 500
                max_poll_records: 500
                
                # Session settings
                session_timeout_ms: 30000
                heartbeat_interval_ms: 3000
                max_poll_interval_ms: 300000
                
                # Error handling
                retry_backoff_ms: 100
                reconnect_backoff_ms: 50
            }
            
            # Topic configuration
            topics: {
                user_events: {
                    name: "user.events"
                    partitions: 3
                    replication_factor: 2
                    retention_ms: 604800000  # 7 days
                },
                order_events: {
                    name: "order.events"
                    partitions: 6
                    replication_factor: 2
                    retention_ms: 2592000000  # 30 days
                },
                notification_events: {
                    name: "notification.events"
                    partitions: 2
                    replication_factor: 1
                    retention_ms: 86400000  # 1 day
                }
            }
        }
        
        # RabbitMQ configuration
        rabbitmq: {
            enabled: events.broker.type == "rabbitmq"
            host: env("RABBITMQ_HOST", "localhost")
            port: env("RABBITMQ_PORT", "5672")
            username: env("RABBITMQ_USER", "guest")
            password: env("RABBITMQ_PASS", "guest")
            virtual_host: env("RABBITMQ_VHOST", "/")
            
            # Connection settings
            connection_timeout: "30s"
            requested_heartbeat: "60s"
            
            # Publisher settings
            publisher_confirms: true
            publisher_returns: true
            
            # Consumer settings
            listener: {
                type: "simple"  # simple, direct
                acknowledge_mode: "manual"
                concurrency: 5
                max_concurrency: 10
                prefetch: 10
                
                # Retry settings
                retry_enabled: true
                max_attempts: 3
                initial_interval: "1s"
                multiplier: 2.0
                max_interval: "10s"
            }
            
            # Exchange and queue configuration
            exchanges: {
                user_exchange: {
                    name: "user.exchange"
                    type: "topic"
                    durable: true
                    auto_delete: false
                },
                order_exchange: {
                    name: "order.exchange"
                    type: "topic"
                    durable: true
                    auto_delete: false
                }
            }
            
            queues: {
                user_created_queue: {
                    name: "user.created.queue"
                    durable: true
                    exclusive: false
                    auto_delete: false
                    routing_key: "user.created"
                    exchange: "user.exchange"
                },
                order_placed_queue: {
                    name: "order.placed.queue"
                    durable: true
                    exclusive: false
                    auto_delete: false
                    routing_key: "order.placed"
                    exchange: "order.exchange"
                }
            }
        }
    }
    
    # Event sourcing configuration
    event_sourcing: {
        enabled: env("EVENT_SOURCING_ENABLED", "false") == "true"
        
        # Event store configuration
        event_store: {
            type: "database"  # database, eventstore, axon
            
            # Database event store
            database: {
                table_name: "event_store"
                schema: "events"
                
                # Partitioning strategy
                partitioning: {
                    enabled: true
                    strategy: "by_aggregate_id"
                    partition_size: 1000000  # 1M events per partition
                }
                
                # Snapshot configuration
                snapshots: {
                    enabled: true
                    frequency: 100  # Take snapshot every 100 events
                    table_name: "snapshots"
                }
            }
        }
        
        # CQRS configuration
        cqrs: {
            enabled: events.event_sourcing.enabled
            
            # Command side
            command: {
                handlers_package: "com.myapp.command.handlers"
                validation_enabled: true
                
                # Command bus configuration
                bus: {
                    type: "simple"  # simple, axon
                    interceptors: [
                        "ValidationInterceptor",
                        "LoggingInterceptor",
                        "MetricsInterceptor"
                    ]
                }
            }
            
            # Query side
            query: {
                handlers_package: "com.myapp.query.handlers"
                projections_package: "com.myapp.projections"
                
                # Query bus configuration
                bus: {
                    type: "simple"
                    interceptors: [
                        "LoggingInterceptor",
                        "CachingInterceptor",
                        "MetricsInterceptor"
                    ]
                }
            }
            
            # Saga configuration
            sagas: {
                enabled: true
                package: "com.myapp.sagas"
                
                # Saga store
                store: {
                    type: "database"
                    table_name: "saga_store"
                }
            }
        }
    }
    
    # Event streaming
    streaming: {
        enabled: env("EVENT_STREAMING_ENABLED", "false") == "true"
        
        # Kafka Streams configuration
        kafka_streams: {
            enabled: events.streaming.enabled && events.broker.type == "kafka"
            application_id: env("KAFKA_STREAMS_APP_ID", "myapp-streams")
            
            # Processing configuration
            processing: {
                guarantee: "exactly_once_v2"  # at_least_once, exactly_once, exactly_once_v2
                commit_interval_ms: 30000
                cache_max_bytes_buffering: 10485760  # 10MB
                
                # State store configuration
                state_store: {
                    dir: "/tmp/kafka-streams"
                    cleanup_policy: "delete"
                }
            }
            
            # Topology configuration
            topologies: {
                user_analytics: {
                    input_topics: ["user.events"]
                    output_topics: ["user.analytics"]
                    
                    # Processing logic
                    operations: [
                        {
                            type: "filter"
                            predicate: "event.type == 'USER_CREATED'"
                        },
                        {
                            type: "groupBy"
                            key_selector: "event.data.region"
                        },
                        {
                            type: "count"
                            window: "1h"
                        }
                    ]
                }
            }
        }
    }
}
</pre>

<h2>Java Event-Driven Configuration</h2>
<pre>
// EventDrivenConfiguration.java
@Configuration
@EnableKafka
@EnableRabbit
public class EventDrivenConfiguration {
    
    @Value("#{${events.broker.kafka}}")
    private Map&lt;String, Object&gt; kafkaConfig;
    
    @Value("#{${events.broker.rabbitmq}}")
    private Map&lt;String, Object&gt; rabbitmqConfig;
    
    // Kafka Configuration
    @Bean
    @ConditionalOnProperty(name = "events.broker.kafka.enabled", havingValue = "true")
    public ProducerFactory&lt;String, Object&gt; producerFactory() {
        Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();
        
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaConfig.get("bootstrap_servers"));
        
        Map&lt;String, Object&gt; producer = (Map&lt;String, Object&gt;) kafkaConfig.get("producer");
        if (producer != null) {
            props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, producer.get("key_serializer"));
            props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, producer.get("value_serializer"));
            props.put(ProducerConfig.BATCH_SIZE_CONFIG, producer.get("batch_size"));
            props.put(ProducerConfig.LINGER_MS_CONFIG, producer.get("linger_ms"));
            props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, producer.get("compression_type"));
            props.put(ProducerConfig.ACKS_CONFIG, producer.get("acks"));
            props.put(ProducerConfig.RETRIES_CONFIG, producer.get("retries"));
            props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, producer.get("enable_idempotence"));
        }
        
        return new DefaultKafkaProducerFactory&lt;&gt;(props);
    }
    
    @Bean
    @ConditionalOnProperty(name = "events.broker.kafka.enabled", havingValue = "true")
    public KafkaTemplate&lt;String, Object&gt; kafkaTemplate() {
        return new KafkaTemplate&lt;&gt;(producerFactory());
    }
    
    @Bean
    @ConditionalOnProperty(name = "events.broker.kafka.enabled", havingValue = "true")
    public ConsumerFactory&lt;String, Object&gt; consumerFactory() {
        Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();
        
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaConfig.get("bootstrap_servers"));
        
        Map&lt;String, Object&gt; consumer = (Map&lt;String, Object&gt;) kafkaConfig.get("consumer");
        if (consumer != null) {
            props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, consumer.get("key_deserializer"));
            props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, consumer.get("value_deserializer"));
            props.put(ConsumerConfig.GROUP_ID_CONFIG, consumer.get("group_id"));
            props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, consumer.get("auto_offset_reset"));
            props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, consumer.get("enable_auto_commit"));
            props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, consumer.get("max_poll_records"));
        }
        
        return new DefaultKafkaConsumerFactory&lt;&gt;(props);
    }
    
    @Bean
    @ConditionalOnProperty(name = "events.broker.kafka.enabled", havingValue = "true")
    public ConcurrentKafkaListenerContainerFactory&lt;String, Object&gt; kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory&lt;String, Object&gt; factory = 
            new ConcurrentKafkaListenerContainerFactory&lt;&gt;();
        factory.setConsumerFactory(consumerFactory());
        
        // Configure error handling
        factory.setCommonErrorHandler(new DefaultErrorHandler(new FixedBackOff(1000L, 3)));
        
        return factory;
    }
    
    // Event Sourcing Configuration
    @Bean
    @ConditionalOnProperty(name = "events.event_sourcing.enabled", havingValue = "true")
    public EventStore eventStore() {
        return new DatabaseEventStore(); // Custom implementation
    }
    
    @Bean
    @ConditionalOnProperty(name = "events.event_sourcing.cqrs.enabled", havingValue = "true")
    public CommandBus commandBus() {
        return new SimpleCommandBus(); // Custom implementation
    }
    
    @Bean
    @ConditionalOnProperty(name = "events.event_sourcing.cqrs.enabled", havingValue = "true")
    public QueryBus queryBus() {
        return new SimpleQueryBus(); // Custom implementation
    }
}

// Event publishing service
@Service
public class EventPublisher {
    
    private final KafkaTemplate&lt;String, Object&gt; kafkaTemplate;
    private final RabbitTemplate rabbitTemplate;
    
    public EventPublisher(KafkaTemplate&lt;String, Object&gt; kafkaTemplate, RabbitTemplate rabbitTemplate) {
        this.kafkaTemplate = kafkaTemplate;
        this.rabbitTemplate = rabbitTemplate;
    }
    
    public void publishUserEvent(UserEvent event) {
        // Kafka publishing
        if (kafkaTemplate != null) {
            kafkaTemplate.send("user.events", event.getUserId().toString(), event);
        }
        
        // RabbitMQ publishing
        if (rabbitTemplate != null) {
            rabbitTemplate.convertAndSend("user.exchange", "user." + event.getType().toLowerCase(), event);
        }
    }
    
    public void publishOrderEvent(OrderEvent event) {
        // Kafka publishing
        if (kafkaTemplate != null) {
            kafkaTemplate.send("order.events", event.getOrderId().toString(), event);
        }
        
        // RabbitMQ publishing
        if (rabbitTemplate != null) {
            rabbitTemplate.convertAndSend("order.exchange", "order." + event.getType().toLowerCase(), event);
        }
    }
}

// Event listener example
@Component
public class UserEventListener {
    
    @KafkaListener(topics = "user.events", groupId = "user-processor")
    public void handleUserEvent(UserEvent event) {
        switch (event.getType()) {
            case USER_CREATED:
                handleUserCreated(event);
                break;
            case USER_UPDATED:
                handleUserUpdated(event);
                break;
            case USER_DELETED:
                handleUserDeleted(event);
                break;
        }
    }
    
    @RabbitListener(queues = "user.created.queue")
    public void handleUserCreatedFromRabbit(UserEvent event) {
        handleUserCreated(event);
    }
    
    private void handleUserCreated(UserEvent event) {
        // Process user creation event
        System.out.println("Processing user created event: " + event);
    }
    
    private void handleUserUpdated(UserEvent event) {
        // Process user update event
        System.out.println("Processing user updated event: " + event);
    }
    
    private void handleUserDeleted(UserEvent event) {
        // Process user deletion event
        System.out.println("Processing user deleted event: " + event);
    }
}
</pre>