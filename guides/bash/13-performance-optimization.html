<h1>Performance Optimization</h1>

<h2>Optimizing TuskLang Applications in Bash</h2>
<p>Implement performance monitoring, caching, and optimization techniques for high-performance bash scripts.</p>

<h3>performance.tsk</h3>
<pre>
# Performance configuration
performance {
    # Monitoring settings
    monitoring: {
        enabled: true
        interval: 5000  # ms
        
        metrics: {
            cpu_usage: @system.cpu.percentage
            memory_usage: @system.memory.used / @system.memory.total
            disk_io: @system.disk.io_rate
            network_io: @system.network.throughput
            
            # Application metrics
            request_rate: @app.requests_per_second
            response_time: @app.response_time_ms
            error_rate: @app.errors / @app.requests
            queue_size: @app.queue.length
        }
        
        thresholds: {
            cpu_critical: 90
            memory_critical: 85
            response_time_warn: 500
            error_rate_warn: 0.05
        }
    }
    
    # Caching strategies
    caching: {
        # Memory cache
        memory: {
            enabled: true
            max_size: "100MB"
            eviction: "lru"  # least recently used
            ttl: "5m"
            
            keys: {
                user_data: { ttl: "10m", refresh: true },
                config: { ttl: "1h", refresh: false },
                computed: { ttl: "30s", refresh: true }
            }
        }
        
        # Disk cache
        disk: {
            enabled: true
            path: "./cache"
            max_size: "1GB"
            
            compression: {
                enabled: true
                algorithm: "gzip"
                level: 6
            }
        }
        
        # Distributed cache
        redis: {
            enabled: @env.REDIS_URL != null
            url: @env.REDIS_URL
            
            namespaces: {
                session: { prefix: "sess:", ttl: "30m" },
                api: { prefix: "api:", ttl: "5m" },
                compute: { prefix: "comp:", ttl: "1m" }
            }
        }
    }
    
    # Query optimization
    database: {
        # Connection pooling
        pool: {
            min: 2
            max: 10
            idle_timeout: "30s"
            
            # Dynamic sizing
            scale: @optimize("db_pool_size", {
                metric: "connection_wait_time",
                target: 10,  # ms
                min: @pool.min,
                max: @pool.max
            })
        }
        
        # Query caching
        query_cache: {
            enabled: true
            size: "50MB"
            
            # Cache key generation
            key: @hash("md5", @query.sql + @query.params)
            
            # Invalidation rules
            invalidate: {
                on_write: true,
                tables: ["users", "posts", "comments"],
                patterns: ["SELECT COUNT", "SELECT SUM"]
            }
        }
        
        # Prepared statements
        prepared: {
            enabled: true
            cache_size: 100
            
            statements: {
                get_user: "SELECT * FROM users WHERE id = ?",
                list_posts: "SELECT * FROM posts WHERE status = ? LIMIT ?",
                update_stats: "UPDATE stats SET views = views + 1 WHERE id = ?"
            }
        }
    }
    
    # Code optimization
    optimization: {
        # JIT compilation
        jit: {
            enabled: @php.jit_available
            buffer_size: "100M"
            
            hot_functions: @profile.hot_functions(threshold: 1000)
        }
        
        # Lazy loading
        lazy: {
            enabled: true
            
            modules: {
                heavy_lib: @lazy(() => require("./heavy_lib")),
                analytics: @lazy(() => require("./analytics")),
                export: @lazy(() => require("./export"))
            }
        }
        
        # Memoization
        memoize: {
            functions: [
                "calculateHash",
                "parseConfig",
                "validateSchema"
            ],
            
            max_cache: 1000,
            ttl: "10m"
        }
    }
    
    # Resource limits
    limits: {
        # Memory limits
        memory: {
            max: "512MB",
            warning: "400MB",
            
            gc: {
                threshold: "100MB",
                interval: "30s"
            }
        },
        
        # CPU limits
        cpu: {
            max_percentage: 80,
            nice: 10  # Process priority
        },
        
        # Rate limiting
        rate_limits: {
            api: { window: "1m", max: 100 },
            uploads: { window: "1h", max: 10 },
            exports: { window: "1d", max: 100 }
        }
    }
    
    # Profiling
    profiling: {
        enabled: @env.PROFILE || false
        
        targets: {
            cpu: { enabled: true, sampling: 100 },
            memory: { enabled: true, interval: "1s" },
            io: { enabled: true }
        },
        
        output: {
            format: "flamegraph",
            path: "./profiles",
            
            # Auto-profile slow requests
            auto_profile: {
                enabled: true,
                threshold: 1000,  # ms
                max_profiles: 100
            }
        }
    }
}

# Optimization rules
rules {
    # Batch processing
    batching: {
        # Database writes
        db_writes: {
            enabled: true
            size: 100
            timeout: "100ms"
            
            handler: @batch.process(@queue.db_writes)
        }
        
        # API calls
        api_calls: {
            enabled: true
            size: 50
            timeout: "200ms"
            
            handler: @batch.api(@queue.api_calls)
        }
    }
    
    # Parallel processing
    parallel: {
        # Worker configuration
        workers: @cpu.count * 2
        
        tasks: {
            image_processing: { workers: 4, priority: "low" },
            data_import: { workers: 2, priority: "normal" },
            report_generation: { workers: 1, priority: "high" }
        }
    }
}
</pre>

<h3>Bash Performance Implementation</h3>
<pre>
#!/bin/bash

# TuskLang Performance Optimization Library

# Global performance state
declare -A PERF_METRICS
declare -A PERF_CACHE
declare -A PERF_TIMERS
declare -A PERF_COUNTERS
PERF_START_TIME=$(date +%s%N)

# Initialize performance monitoring
tusk_perf_init() {
    # Set process nice level
    renice 10 $$ >/dev/null 2>&1 || true
    
    # Initialize metrics
    PERF_METRICS[start_time]=$PERF_START_TIME
    PERF_METRICS[pid]=$$
    
    # Start monitoring
    tusk_perf_monitor_start &
    PERF_MONITOR_PID=$!
}

# Performance timer
tusk_perf_timer_start() {
    local name="$1"
    PERF_TIMERS[$name]=$(date +%s%N)
}

tusk_perf_timer_end() {
    local name="$1"
    local start_time="${PERF_TIMERS[$name]}"
    local end_time=$(date +%s%N)
    
    if [ -n "$start_time" ]; then
        local duration=$((end_time - start_time))
        PERF_METRICS[timer_$name]=$duration
        
        # Convert to milliseconds for display
        local ms=$((duration / 1000000))
        echo "${name}: ${ms}ms"
    fi
}

# Performance counter
tusk_perf_counter_inc() {
    local name="$1"
    local amount="${2:-1}"
    
    PERF_COUNTERS[$name]=$((${PERF_COUNTERS[$name]:-0} + amount))
}

# Memory cache implementation
declare -A MEMORY_CACHE
declare -A MEMORY_CACHE_TTL
declare -A MEMORY_CACHE_ACCESS
MEMORY_CACHE_MAX_SIZE=$((100 * 1024 * 1024))  # 100MB
MEMORY_CACHE_CURRENT_SIZE=0

tusk_cache_get() {
    local key="$1"
    local now=$(date +%s)
    
    # Check if key exists
    if [ -z "${MEMORY_CACHE[$key]}" ]; then
        tusk_perf_counter_inc "cache_miss"
        return 1
    fi
    
    # Check TTL
    local ttl="${MEMORY_CACHE_TTL[$key]:-0}"
    if [ "$ttl" -gt 0 ] && [ "$now" -gt "$ttl" ]; then
        tusk_cache_delete "$key"
        tusk_perf_counter_inc "cache_expired"
        return 1
    fi
    
    # Update access time (for LRU)
    MEMORY_CACHE_ACCESS[$key]=$now
    tusk_perf_counter_inc "cache_hit"
    
    echo "${MEMORY_CACHE[$key]}"
    return 0
}

tusk_cache_set() {
    local key="$1"
    local value="$2"
    local ttl="${3:-300}"  # Default 5 minutes
    
    local size=${#value}
    local now=$(date +%s)
    
    # Check cache size limit
    if [ $((MEMORY_CACHE_CURRENT_SIZE + size)) -gt $MEMORY_CACHE_MAX_SIZE ]; then
        tusk_cache_evict_lru $size
    fi
    
    # Store value
    MEMORY_CACHE[$key]="$value"
    MEMORY_CACHE_TTL[$key]=$((now + ttl))
    MEMORY_CACHE_ACCESS[$key]=$now
    MEMORY_CACHE_CURRENT_SIZE=$((MEMORY_CACHE_CURRENT_SIZE + size))
    
    tusk_perf_counter_inc "cache_set"
}

tusk_cache_delete() {
    local key="$1"
    
    if [ -n "${MEMORY_CACHE[$key]}" ]; then
        local size=${#MEMORY_CACHE[$key]}
        unset MEMORY_CACHE[$key]
        unset MEMORY_CACHE_TTL[$key]
        unset MEMORY_CACHE_ACCESS[$key]
        MEMORY_CACHE_CURRENT_SIZE=$((MEMORY_CACHE_CURRENT_SIZE - size))
    fi
}

tusk_cache_evict_lru() {
    local needed_size="$1"
    local freed_size=0
    
    # Sort keys by access time
    local sorted_keys=$(
        for key in "${!MEMORY_CACHE_ACCESS[@]}"; do
            echo "${MEMORY_CACHE_ACCESS[$key]} $key"
        done | sort -n | awk '{print $2}'
    )
    
    # Evict least recently used
    for key in $sorted_keys; do
        [ $freed_size -ge $needed_size ] && break
        
        local size=${#MEMORY_CACHE[$key]}
        tusk_cache_delete "$key"
        freed_size=$((freed_size + size))
        
        tusk_perf_counter_inc "cache_eviction"
    done
}

# Disk cache implementation
DISK_CACHE_PATH="./cache"

tusk_disk_cache_init() {
    mkdir -p "$DISK_CACHE_PATH"
}

tusk_disk_cache_get() {
    local key="$1"
    local cache_file="$DISK_CACHE_PATH/$(echo -n "$key" | md5sum | cut -d' ' -f1)"
    
    if [ -f "$cache_file" ]; then
        # Check if cache is still valid
        local ttl_file="${cache_file}.ttl"
        if [ -f "$ttl_file" ]; then
            local ttl=$(cat "$ttl_file")
            local now=$(date +%s)
            
            if [ "$now" -gt "$ttl" ]; then
                rm -f "$cache_file" "$ttl_file"
                return 1
            fi
        fi
        
        # Decompress if needed
        if [ -f "${cache_file}.gz" ]; then
            gunzip -c "${cache_file}.gz"
        else
            cat "$cache_file"
        fi
        
        return 0
    fi
    
    return 1
}

tusk_disk_cache_set() {
    local key="$1"
    local value="$2"
    local ttl="${3:-3600}"  # Default 1 hour
    local compress="${4:-true}"
    
    local cache_file="$DISK_CACHE_PATH/$(echo -n "$key" | md5sum | cut -d' ' -f1)"
    local ttl_file="${cache_file}.ttl"
    
    # Write TTL
    echo $(($(date +%s) + ttl)) > "$ttl_file"
    
    # Write value (with optional compression)
    if [ "$compress" = "true" ] && [ ${#value} -gt 1024 ]; then
        echo "$value" | gzip -c > "${cache_file}.gz"
    else
        echo "$value" > "$cache_file"
    fi
}

# Memoization
declare -A MEMO_CACHE

tusk_memoize() {
    local func="$1"
    shift
    local args="$*"
    local key="${func}:${args}"
    
    # Check cache
    if [ -n "${MEMO_CACHE[$key]}" ]; then
        echo "${MEMO_CACHE[$key]}"
        return 0
    fi
    
    # Call function and cache result
    local result=$($func "$@")
    MEMO_CACHE[$key]="$result"
    echo "$result"
}

# Batch processing
declare -A BATCH_QUEUES
declare -A BATCH_TIMERS

tusk_batch_add() {
    local queue="$1"
    local item="$2"
    local batch_size="${3:-100}"
    local timeout="${4:-100}"  # ms
    
    # Add to queue
    if [ -z "${BATCH_QUEUES[$queue]}" ]; then
        BATCH_QUEUES[$queue]="$item"
    else
        BATCH_QUEUES[$queue]="${BATCH_QUEUES[$queue]}|$item"
    fi
    
    # Check if batch is full
    local count=$(echo "${BATCH_QUEUES[$queue]}" | tr '|' '\n' | wc -l)
    if [ "$count" -ge "$batch_size" ]; then
        tusk_batch_process "$queue"
    else
        # Set timeout if not already set
        if [ -z "${BATCH_TIMERS[$queue]}" ]; then
            (
                sleep $(echo "scale=3; $timeout/1000" | bc)
                tusk_batch_process "$queue"
            ) &
            BATCH_TIMERS[$queue]=$!
        fi
    fi
}

tusk_batch_process() {
    local queue="$1"
    local items="${BATCH_QUEUES[$queue]}"
    
    [ -z "$items" ] && return
    
    # Clear queue
    unset BATCH_QUEUES[$queue]
    unset BATCH_TIMERS[$queue]
    
    # Process batch
    echo "Processing batch of $(echo "$items" | tr '|' '\n' | wc -l) items"
    # Actual processing logic here
}

# Parallel execution
tusk_parallel() {
    local max_jobs="${1:-4}"
    shift
    local commands=("$@")
    
    local job_count=0
    local pids=()
    
    for cmd in "${commands[@]}"; do
        # Wait if max jobs reached
        while [ $job_count -ge $max_jobs ]; do
            wait -n
            job_count=$((job_count - 1))
        done
        
        # Execute in background
        eval "$cmd" &
        pids+=($!)
        job_count=$((job_count + 1))
    done
    
    # Wait for all jobs
    for pid in "${pids[@]}"; do
        wait "$pid"
    done
}

# System monitoring
tusk_perf_monitor_start() {
    while true; do
        tusk_perf_collect_metrics
        sleep 5
    done
}

tusk_perf_collect_metrics() {
    # CPU usage
    local cpu_usage=$(top -bn1 -p $$ | tail -1 | awk '{print $9}')
    PERF_METRICS[cpu_usage]="$cpu_usage"
    
    # Memory usage
    local mem_info=$(ps -p $$ -o vsz=,rss=)
    local vsz=$(echo "$mem_info" | awk '{print $1}')
    local rss=$(echo "$mem_info" | awk '{print $2}')
    PERF_METRICS[memory_vsz]=$vsz
    PERF_METRICS[memory_rss]=$rss
    
    # File descriptors
    local fd_count=$(ls /proc/$$/fd 2>/dev/null | wc -l)
    PERF_METRICS[fd_count]=$fd_count
    
    # Check thresholds
    tusk_perf_check_thresholds
}

tusk_perf_check_thresholds() {
    # CPU threshold
    local cpu_usage="${PERF_METRICS[cpu_usage]:-0}"
    if (( $(echo "$cpu_usage > 90" | bc -l) )); then
        echo "WARNING: High CPU usage: ${cpu_usage}%" >&2
    fi
    
    # Memory threshold
    local mem_rss="${PERF_METRICS[memory_rss]:-0}"
    local mem_mb=$((mem_rss / 1024))
    if [ $mem_mb -gt 400 ]; then
        echo "WARNING: High memory usage: ${mem_mb}MB" >&2
    fi
}

# Query optimization
tusk_optimize_query() {
    local query="$1"
    
    # Check query cache
    local cache_key=$(echo -n "$query" | md5sum | cut -d' ' -f1)
    if tusk_cache_get "query:$cache_key"; then
        return 0
    fi
    
    # Execute query with timing
    tusk_perf_timer_start "query"
    local result=$(tusk_db_exec "$query")
    tusk_perf_timer_end "query"
    
    # Cache result
    tusk_cache_set "query:$cache_key" "$result" 300
    
    echo "$result"
}

# Connection pooling
declare -a DB_POOL
DB_POOL_MIN=2
DB_POOL_MAX=10

tusk_pool_init() {
    # Create initial connections
    for ((i=0; i<DB_POOL_MIN; i++)); do
        tusk_pool_create_connection
    done
}

tusk_pool_get_connection() {
    # Find available connection
    for i in "${!DB_POOL[@]}"; do
        local conn="${DB_POOL[$i]}"
        if [ -n "$conn" ]; then
            unset DB_POOL[$i]
            echo "$conn"
            return 0
        fi
    done
    
    # Create new connection if under limit
    if [ ${#DB_POOL[@]} -lt $DB_POOL_MAX ]; then
        tusk_pool_create_connection
    fi
    
    return 1
}

tusk_pool_return_connection() {
    local conn="$1"
    DB_POOL+=("$conn")
}

# Profiling
tusk_profile() {
    local name="$1"
    local command="$2"
    
    # Start profiling
    local start_time=$(date +%s%N)
    local start_mem=$(ps -p $$ -o rss= | tr -d ' ')
    
    # Execute command
    eval "$command"
    local exit_code=$?
    
    # End profiling
    local end_time=$(date +%s%N)
    local end_mem=$(ps -p $$ -o rss= | tr -d ' ')
    
    # Calculate metrics
    local duration=$((end_time - start_time))
    local mem_delta=$((end_mem - start_mem))
    
    # Store profile
    cat >> "./profiles/${name}.profile" <<EOF
{
    "timestamp": $(date +%s),
    "duration_ns": $duration,
    "duration_ms": $((duration / 1000000)),
    "memory_delta_kb": $mem_delta,
    "exit_code": $exit_code
}
EOF
    
    return $exit_code
}

# Performance report
tusk_perf_report() {
    echo "=== Performance Report ==="
    echo "Uptime: $(($(date +%s) - ${PERF_START_TIME%??????}))s"
    echo ""
    
    echo "Metrics:"
    for metric in "${!PERF_METRICS[@]}"; do
        echo "  $metric: ${PERF_METRICS[$metric]}"
    done
    echo ""
    
    echo "Counters:"
    for counter in "${!PERF_COUNTERS[@]}"; do
        echo "  $counter: ${PERF_COUNTERS[$counter]}"
    done
    echo ""
    
    echo "Cache Statistics:"
    local total_requests=$((${PERF_COUNTERS[cache_hit]:-0} + ${PERF_COUNTERS[cache_miss]:-0}))
    if [ $total_requests -gt 0 ]; then
        local hit_rate=$(echo "scale=2; ${PERF_COUNTERS[cache_hit]:-0} * 100 / $total_requests" | bc)
        echo "  Hit rate: ${hit_rate}%"
    fi
    echo "  Cache size: ${#MEMORY_CACHE[@]} items"
    echo "  Memory used: $((MEMORY_CACHE_CURRENT_SIZE / 1024))KB"
}

# Cleanup
tusk_perf_cleanup() {
    [ -n "$PERF_MONITOR_PID" ] && kill $PERF_MONITOR_PID 2>/dev/null || true
    tusk_perf_report
}
</pre>

<h3>Usage Example</h3>
<pre>
#!/bin/bash

# Load performance library
source /usr/local/lib/tusklang-performance.sh

# Initialize performance monitoring
tusk_perf_init
trap tusk_perf_cleanup EXIT

echo "=== Performance Optimization Demo ==="

# 1. Timer usage
echo -e "\n1. Performance Timing:"

tusk_perf_timer_start "total"

# Simulate some work
tusk_perf_timer_start "computation"
for i in {1..1000}; do
    result=$((i * i))
done
tusk_perf_timer_end "computation"

# 2. Memory caching
echo -e "\n2. Memory Cache:"

compute_expensive() {
    local input="$1"
    echo "Computing for $input..." >&2
    sleep 0.5  # Simulate expensive operation
    echo $((input * input * input))
}

# First call - miss
tusk_perf_timer_start "cache_miss"
result=$(tusk_cache_get "compute:5" || {
    value=$(compute_expensive 5)
    tusk_cache_set "compute:5" "$value" 60
    echo "$value"
})
tusk_perf_timer_end "cache_miss"
echo "Result: $result"

# Second call - hit
tusk_perf_timer_start "cache_hit"
result=$(tusk_cache_get "compute:5" || compute_expensive 5)
tusk_perf_timer_end "cache_hit"
echo "Cached result: $result"

# 3. Disk caching
echo -e "\n3. Disk Cache:"

tusk_disk_cache_init

# Cache large data
large_data=$(seq 1 10000 | tr '\n' ' ')
echo "Caching ${#large_data} bytes to disk..."

tusk_perf_timer_start "disk_write"
tusk_disk_cache_set "large_data" "$large_data" 3600 true
tusk_perf_timer_end "disk_write"

tusk_perf_timer_start "disk_read"
cached_data=$(tusk_disk_cache_get "large_data")
tusk_perf_timer_end "disk_read"

echo "Retrieved ${#cached_data} bytes from disk cache"

# 4. Memoization
echo -e "\n4. Memoization:"

fibonacci() {
    local n="$1"
    [ "$n" -le 1 ] && echo "$n" && return
    
    local a=$(tusk_memoize fibonacci $((n-1)))
    local b=$(tusk_memoize fibonacci $((n-2)))
    echo $((a + b))
}

tusk_perf_timer_start "fib_memo"
for i in {1..20}; do
    result=$(fibonacci $i)
    echo -n "$result "
done
echo
tusk_perf_timer_end "fib_memo"

# 5. Batch processing
echo -e "\n5. Batch Processing:"

# Simulate adding items to batch
for i in {1..25}; do
    tusk_batch_add "process_queue" "item_$i" 10 200
    [ $((i % 5)) -eq 0 ] && sleep 0.1
done

# Wait for batch processing
sleep 0.5

# 6. Parallel execution
echo -e "\n6. Parallel Execution:"

slow_task() {
    local id="$1"
    echo "Task $id starting..."
    sleep 1
    echo "Task $id completed"
}

# Sequential execution
tusk_perf_timer_start "sequential"
for i in {1..4}; do
    slow_task $i
done
tusk_perf_timer_end "sequential"

# Parallel execution
tusk_perf_timer_start "parallel"
commands=()
for i in {1..4}; do
    commands+=("slow_task $i")
done
tusk_parallel 4 "${commands[@]}"
tusk_perf_timer_end "parallel"

# 7. Query optimization
echo -e "\n7. Query Optimization:"

# Simulate database query
tusk_db_exec() {
    echo "Executing: $1" >&2
    sleep 0.2  # Simulate query time
    echo '{"result":"data"}'
}

# First query - cache miss
query="SELECT * FROM users WHERE active = 1"
tusk_perf_timer_start "query1"
result=$(tusk_optimize_query "$query")
tusk_perf_timer_end "query1"

# Same query - cache hit
tusk_perf_timer_start "query2"
result=$(tusk_optimize_query "$query")
tusk_perf_timer_end "query2"

# 8. Profiling
echo -e "\n8. Profiling:"

mkdir -p ./profiles

heavy_computation() {
    local sum=0
    for i in {1..10000}; do
        sum=$((sum + i))
    done
    echo $sum
}

tusk_profile "heavy_computation" "heavy_computation"

# 9. Resource monitoring
echo -e "\n9. Resource Monitoring:"

# Simulate some load
tusk_perf_timer_start "load_test"
for i in {1..5}; do
    # CPU intensive
    for j in {1..1000}; do
        result=$((j * j * j))
    done
    
    # Memory allocation
    data=$(seq 1 1000)
    
    # Counter updates
    tusk_perf_counter_inc "iterations"
    tusk_perf_counter_inc "calculations" 1000
done
tusk_perf_timer_end "load_test"

# 10. Performance analysis
echo -e "\n10. Performance Analysis:"

# Check cache performance
echo "Cache performance:"
echo "  Memory cache entries: ${#MEMORY_CACHE[@]}"
echo "  Memoization cache entries: ${#MEMO_CACHE[@]}"

# Memory usage
current_mem=$(ps -p $$ -o rss= | tr -d ' ')
echo "  Current memory: $((current_mem / 1024))MB"

# File descriptors
fd_count=$(ls /proc/$$/fd 2>/dev/null | wc -l)
echo "  Open file descriptors: $fd_count"

# Final timing
tusk_perf_timer_end "total"

# Generate report
echo -e "\n=== Final Performance Report ==="
tusk_perf_report

# Cleanup
rm -rf ./cache ./profiles
</pre>

<p>TuskLang performance optimization in bash provides comprehensive tools for monitoring, caching, parallel processing, and profiling to build high-performance shell applications.</p>