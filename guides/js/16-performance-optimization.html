<h1>Performance & Optimization</h1>

<h2>Optimizing TuskLang Applications in JavaScript</h2>
<p>Advanced caching, lazy loading, and performance optimization strategies for TuskLang-based JavaScript applications.</p>

<h3>performance.tsk</h3>
<pre>
# Performance configuration
performance {
    # Caching strategies
    cache {
        # Memory cache with LRU eviction
        memory: {
            max_size: "100MB",
            max_items: 10000,
            ttl: "5m",
            algorithm: "lru"
        },
        
        # Redis cache for distributed systems
        redis: {
            enabled: @env.REDIS_ENABLED|false,
            prefix: "tusk:",
            ttl: "1h",
            compression: true
        },
        
        # File-based cache
        file: {
            directory: "./cache",
            max_size: "1GB",
            cleanup_interval: "1h"
        },
        
        # Cache key strategies
        keys: {
            user_data: "user:{{id}}:{{version}}",
            api_response: "api:{{method}}:{{path}}:{{hash(query)}}",
            computed: "computed:{{name}}:{{hash(inputs)}}"
        }
    },
    
    # Lazy loading configuration
    lazy {
        # Module loading
        modules: {
            preload: ["core", "utils"],
            demand: {
                "heavy-lib": @when(@route.includes("/analytics")),
                "charts": @when(@user.features.includes("charts")),
                "admin": @when(@user.role === "admin")
            }
        },
        
        # Data loading
        data: {
            strategy: "progressive",
            batch_size: 100,
            
            loaders: {
                users: @lazy(@fetchUsers, { cache: "1h" }),
                posts: @lazy(@fetchPosts, { cache: "30m", preload: 10 }),
                comments: @lazy(@fetchComments, { cache: "5m", batch: 50 })
            }
        },
        
        # Component loading
        components: {
            intersection_observer: {
                root_margin: "100px",
                threshold: 0.1
            },
            
            routes: {
                "/dashboard": ["DashboardHeader", "DashboardStats"],
                "/profile": ["ProfileCard", "ActivityFeed"],
                "/admin/*": ["AdminPanel", "AdminTools"]
            }
        }
    },
    
    # Optimization rules
    optimization {
        # Bundle optimization
        bundling: {
            split_chunks: {
                vendor: {
                    test: /node_modules/,
                    name: "vendor",
                    priority: 10
                },
                common: {
                    minChunks: 2,
                    priority: 5,
                    reuseExistingChunk: true
                }
            },
            
            tree_shaking: true,
            minimize: @env.NODE_ENV === "production",
            source_maps: @env.NODE_ENV !== "production"
        },
        
        # Runtime optimization
        runtime: {
            # Debouncing and throttling
            debounce: {
                search: 300,
                save: 1000,
                resize: 150
            },
            
            throttle: {
                scroll: 16,
                api_calls: 100,
                analytics: 1000
            },
            
            # Request batching
            batching: {
                enabled: true,
                window: 10,
                max_batch_size: 100,
                
                endpoints: {
                    "/api/users/batch": ["GET", "POST"],
                    "/api/data/batch": ["GET"]
                }
            }
        },
        
        # Memory management
        memory: {
            # Garbage collection hints
            gc_interval: "5m",
            max_heap_size: "1GB",
            
            # Object pooling
            pools: {
                workers: {
                    min: 2,
                    max: 10,
                    idle_timeout: "30s"
                },
                connections: {
                    min: 5,
                    max: 100,
                    idle_timeout: "1m"
                }
            },
            
            # Weak references for caches
            weak_maps: ["user_sessions", "temp_data", "computed_values"]
        }
    },
    
    # Monitoring and metrics
    monitoring {
        # Performance metrics
        metrics: {
            enabled: true,
            
            collect: {
                response_time: true,
                memory_usage: true,
                cpu_usage: true,
                cache_hit_rate: true,
                error_rate: true
            },
            
            thresholds: {
                response_time: { warn: 200, error: 1000 },
                memory_usage: { warn: "80%", error: "95%" },
                cache_hit_rate: { warn: 0.7, error: 0.5 },
                error_rate: { warn: 0.01, error: 0.05 }
            }
        },
        
        # Performance budgets
        budgets: {
            bundle_size: {
                main: "200KB",
                vendor: "300KB",
                total: "500KB"
            },
            
            load_time: {
                first_contentful_paint: "1s",
                time_to_interactive: "3s",
                total_blocking_time: "300ms"
            },
            
            runtime: {
                api_response: "200ms",
                database_query: "50ms",
                render_time: "16ms"
            }
        }
    },
    
    # Adaptive optimization
    adaptive {
        # Network-aware loading
        network: {
            strategies: {
                "4g": { preload: true, prefetch: true, quality: "high" },
                "3g": { preload: false, prefetch: false, quality: "medium" },
                "2g": { preload: false, prefetch: false, quality: "low", enable_saves: true }
            },
            
            current: @detectNetworkType(),
            strategy: @var.adaptive.network.strategies[@var.adaptive.network.current]
        },
        
        # Device-aware optimization
        device: {
            memory: @detectDeviceMemory(),
            cpu_cores: @detectCPUCores(),
            
            strategies: {
                high_end: { workers: 4, cache_size: "100MB", enable_all_features: true },
                mid_range: { workers: 2, cache_size: "50MB", enable_all_features: true },
                low_end: { workers: 1, cache_size: "20MB", enable_all_features: false }
            },
            
            profile: @when({
                @var.adaptive.device.memory > 4 && @var.adaptive.device.cpu_cores > 4: "high_end",
                @var.adaptive.device.memory > 2 && @var.adaptive.device.cpu_cores > 2: "mid_range",
                default: "low_end"
            })
        }
    }
}

# Performance utilities
utils {
    # Memoization configurations
    memoize: {
        expensive_calculation: {
            max_size: 100,
            ttl: "10m",
            key_generator: @hash(arguments)
        },
        
        api_calls: {
            max_size: 1000,
            ttl: "5m",
            key_generator: @concat(method, ":", url, ":", @hash(params))
        }
    },
    
    # Virtual scrolling
    virtual_scroll: {
        item_height: 50,
        buffer_size: 5,
        scroll_debounce: 10,
        recycle_views: true
    },
    
    # Image optimization
    images: {
        lazy_load: true,
        intersection_margin: "50px",
        
        formats: {
            webp: { quality: 85, enabled: @supportsWebP() },
            avif: { quality: 80, enabled: @supportsAVIF() }
        },
        
        sizes: {
            thumbnail: { width: 150, height: 150 },
            small: { width: 300, height: 300 },
            medium: { width: 600, height: 600 },
            large: { width: 1200, height: 1200 }
        }
    }
}
</pre>

<h3>JavaScript Performance Implementation</h3>
<pre>
// Performance optimization system
class PerformanceOptimizer {
    constructor(config) {
        this.config = config;
        this.cache = new CacheManager(config.performance.cache);
        this.metrics = new MetricsCollector(config.performance.monitoring.metrics);
        this.lazyLoader = new LazyLoader(config.performance.lazy);
        
        this.initializeOptimizations();
    }
    
    initializeOptimizations() {
        this.setupCaching();
        this.setupLazyLoading();
        this.setupRuntimeOptimizations();
        this.setupMonitoring();
        this.setupAdaptiveOptimization();
    }
    
    setupCaching() {
        // Memory cache with LRU
        this.memoryCache = new LRUCache({
            max: this.config.performance.cache.memory.max_items,
            maxSize: this.parseSize(this.config.performance.cache.memory.max_size),
            ttl: this.parseTTL(this.config.performance.cache.memory.ttl),
            sizeCalculation: (value) => JSON.stringify(value).length
        });
        
        // Redis cache if enabled
        if (this.config.performance.cache.redis.enabled) {
            const Redis = require('ioredis');
            this.redisCache = new Redis();
            
            // Add compression middleware
            if (this.config.performance.cache.redis.compression) {
                const zlib = require('zlib');
                
                this.redisCache.defineCommand('setCompressed', {
                    numberOfKeys: 1,
                    lua: `
                        local key = KEYS[1]
                        local value = ARGV[1]
                        local ttl = ARGV[2]
                        redis.call('SET', key, value)
                        if ttl then
                            redis.call('EXPIRE', key, ttl)
                        end
                        return 'OK'
                    `
                });
            }
        }
    }
    
    setupLazyLoading() {
        // Module lazy loading
        this.moduleLoader = new ModuleLoader(this.config.performance.lazy.modules);
        
        // Data lazy loading
        this.dataLoader = new DataLoader(this.config.performance.lazy.data);
        
        // Component lazy loading with Intersection Observer
        if (typeof IntersectionObserver !== 'undefined') {
            this.componentObserver = new IntersectionObserver(
                (entries) => this.handleIntersection(entries),
                this.config.performance.lazy.components.intersection_observer
            );
        }
    }
    
    setupRuntimeOptimizations() {
        // Debouncing
        this.debouncers = {};
        Object.entries(this.config.performance.optimization.runtime.debounce).forEach(
            ([key, delay]) => {
                this.debouncers[key] = this.debounce(delay);
            }
        );
        
        // Throttling
        this.throttlers = {};
        Object.entries(this.config.performance.optimization.runtime.throttle).forEach(
            ([key, delay]) => {
                this.throttlers[key] = this.throttle(delay);
            }
        );
        
        // Request batching
        if (this.config.performance.optimization.runtime.batching.enabled) {
            this.batcher = new RequestBatcher(
                this.config.performance.optimization.runtime.batching
            );
        }
        
        // Object pooling
        this.pools = {};
        Object.entries(this.config.performance.optimization.memory.pools).forEach(
            ([name, config]) => {
                this.pools[name] = new ObjectPool(config);
            }
        );
    }
    
    setupMonitoring() {
        // Performance observer
        if (typeof PerformanceObserver !== 'undefined') {
            const observer = new PerformanceObserver((list) => {
                for (const entry of list.getEntries()) {
                    this.metrics.record(entry.name, {
                        duration: entry.duration,
                        startTime: entry.startTime,
                        type: entry.entryType
                    });
                }
            });
            
            observer.observe({ entryTypes: ['measure', 'navigation', 'resource'] });
        }
        
        // Memory monitoring
        if (performance.memory) {
            setInterval(() => {
                this.metrics.record('memory', {
                    used: performance.memory.usedJSHeapSize,
                    total: performance.memory.totalJSHeapSize,
                    limit: performance.memory.jsHeapSizeLimit
                });
            }, 30000); // Every 30 seconds
        }
        
        // Budget monitoring
        this.budgetMonitor = new BudgetMonitor(this.config.performance.monitoring.budgets);
    }
    
    setupAdaptiveOptimization() {
        // Network detection
        if ('connection' in navigator) {
            this.networkType = navigator.connection.effectiveType;
            navigator.connection.addEventListener('change', () => {
                this.networkType = navigator.connection.effectiveType;
                this.applyNetworkStrategy();
            });
        }
        
        // Device detection
        this.deviceProfile = this.detectDeviceProfile();
        this.applyDeviceStrategy();
    }
    
    // Caching methods
    async cache(key, factory, options = {}) {
        const ttl = options.ttl || this.config.performance.cache.memory.ttl;
        const cacheKey = this.generateCacheKey(key, options);
        
        // Try memory cache first
        let value = this.memoryCache.get(cacheKey);
        if (value !== undefined) {
            this.metrics.increment('cache.hits');
            return value;
        }
        
        // Try Redis cache if available
        if (this.redisCache && options.distributed !== false) {
            value = await this.getFromRedis(cacheKey);
            if (value !== null) {
                this.memoryCache.set(cacheKey, value);
                this.metrics.increment('cache.hits');
                return value;
            }
        }
        
        // Cache miss - execute factory
        this.metrics.increment('cache.misses');
        value = await factory();
        
        // Store in caches
        this.memoryCache.set(cacheKey, value);
        if (this.redisCache && options.distributed !== false) {
            await this.setInRedis(cacheKey, value, ttl);
        }
        
        return value;
    }
    
    generateCacheKey(key, options) {
        if (typeof key === 'string') return key;
        
        // Use configured key strategy
        const strategy = this.config.performance.cache.keys[key.type];
        if (strategy) {
            return strategy.replace(/\{\{(\w+)\}\}/g, (match, prop) => {
                if (prop === 'hash') {
                    return this.hash(key[prop]);
                }
                return key[prop] || match;
            });
        }
        
        return this.hash(key);
    }
    
    // Lazy loading methods
    lazy(loader, options = {}) {
        return new Proxy({}, {
            get: (target, prop) => {
                if (!target[prop]) {
                    target[prop] = this.loadLazy(loader, prop, options);
                }
                return target[prop];
            }
        });
    }
    
    async loadLazy(loader, prop, options) {
        const start = performance.now();
        
        try {
            const result = await loader(prop);
            const duration = performance.now() - start;
            
            this.metrics.record('lazy.load', {
                property: prop,
                duration,
                size: JSON.stringify(result).length
            });
            
            if (options.cache) {
                return this.cache(`lazy:${prop}`, () => result, { ttl: options.cache });
            }
            
            return result;
        } catch (error) {
            this.metrics.increment('lazy.errors');
            throw error;
        }
    }
    
    // Utility methods
    debounce(delay) {
        let timeoutId;
        return (fn) => {
            return (...args) => {
                clearTimeout(timeoutId);
                timeoutId = setTimeout(() => fn(...args), delay);
            };
        };
    }
    
    throttle(delay) {
        let lastCall = 0;
        return (fn) => {
            return (...args) => {
                const now = Date.now();
                if (now - lastCall >= delay) {
                    lastCall = now;
                    return fn(...args);
                }
            };
        };
    }
    
    memoize(fn, options = {}) {
        const cache = new LRUCache({
            max: options.max_size || 100,
            ttl: this.parseTTL(options.ttl || '10m')
        });
        
        return (...args) => {
            const key = options.key_generator 
                ? options.key_generator(args)
                : JSON.stringify(args);
            
            if (cache.has(key)) {
                return cache.get(key);
            }
            
            const result = fn(...args);
            cache.set(key, result);
            return result;
        };
    }
    
    parseSize(size) {
        const units = { KB: 1024, MB: 1024 * 1024, GB: 1024 * 1024 * 1024 };
        const match = size.match(/^(\d+)(KB|MB|GB)$/);
        if (match) {
            return parseInt(match[1]) * units[match[2]];
        }
        return parseInt(size);
    }
    
    parseTTL(ttl) {
        const units = { s: 1000, m: 60000, h: 3600000, d: 86400000 };
        const match = ttl.match(/^(\d+)([smhd])$/);
        if (match) {
            return parseInt(match[1]) * units[match[2]];
        }
        return parseInt(ttl);
    }
    
    hash(obj) {
        const crypto = require('crypto');
        return crypto
            .createHash('md5')
            .update(JSON.stringify(obj))
            .digest('hex');
    }
    
    detectDeviceProfile() {
        const memory = navigator.deviceMemory || 4; // GB
        const cores = navigator.hardwareConcurrency || 4;
        
        if (memory > 4 && cores > 4) return 'high_end';
        if (memory > 2 && cores > 2) return 'mid_range';
        return 'low_end';
    }
    
    applyNetworkStrategy() {
        const strategy = this.config.performance.adaptive.network.strategies[this.networkType];
        if (strategy) {
            // Apply network-specific optimizations
            this.config.preload = strategy.preload;
            this.config.prefetch = strategy.prefetch;
            this.config.quality = strategy.quality;
        }
    }
    
    applyDeviceStrategy() {
        const strategy = this.config.performance.adaptive.device.strategies[this.deviceProfile];
        if (strategy) {
            // Apply device-specific optimizations
            this.config.workers = strategy.workers;
            this.config.cache_size = strategy.cache_size;
            this.config.features = strategy.enable_all_features;
        }
    }
}

// Request batcher
class RequestBatcher {
    constructor(config) {
        this.config = config;
        this.queues = new Map();
        this.timers = new Map();
    }
    
    batch(endpoint, request) {
        return new Promise((resolve, reject) => {
            if (!this.queues.has(endpoint)) {
                this.queues.set(endpoint, []);
            }
            
            this.queues.get(endpoint).push({ request, resolve, reject });
            
            // Clear existing timer
            if (this.timers.has(endpoint)) {
                clearTimeout(this.timers.get(endpoint));
            }
            
            // Set new timer
            const timer = setTimeout(() => {
                this.flush(endpoint);
            }, this.config.window);
            
            this.timers.set(endpoint, timer);
            
            // Flush if batch is full
            if (this.queues.get(endpoint).length >= this.config.max_batch_size) {
                this.flush(endpoint);
            }
        });
    }
    
    async flush(endpoint) {
        const queue = this.queues.get(endpoint);
        if (!queue || queue.length === 0) return;
        
        // Clear queue and timer
        this.queues.set(endpoint, []);
        this.timers.delete(endpoint);
        
        try {
            // Send batched request
            const requests = queue.map(item => item.request);
            const responses = await this.sendBatch(endpoint, requests);
            
            // Resolve individual promises
            queue.forEach((item, index) => {
                item.resolve(responses[index]);
            });
        } catch (error) {
            // Reject all promises
            queue.forEach(item => item.reject(error));
        }
    }
    
    async sendBatch(endpoint, requests) {
        const response = await fetch(endpoint, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ batch: requests })
        });
        
        const data = await response.json();
        return data.results;
    }
}

// Usage
const config = TuskLang.parse(fs.readFileSync('performance.tsk', 'utf8'));
const optimizer = new PerformanceOptimizer(config);

// Use caching
const userData = await optimizer.cache('user:123:v1', async () => {
    return await fetchUserData(123);
}, { ttl: '5m' });

// Use memoization
const expensiveCalc = optimizer.memoize((n) => {
    // Expensive calculation
    return fibonacci(n);
}, { max_size: 100, ttl: '10m' });

// Use debouncing
const debouncedSearch = optimizer.debouncers.search((query) => {
    performSearch(query);
});

// Use lazy loading
const lazyData = optimizer.lazy(async (prop) => {
    return await fetchData(prop);
}, { cache: '1h' });

console.log(await lazyData.users); // Loads on first access
</pre>

<p>TuskLang's performance optimization features enable building high-performance JavaScript applications with intelligent caching, lazy loading, and adaptive optimization strategies.</p>